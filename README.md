# bartoc-etl
Prototype ETL pipeline for indexing Bartoc data from MongoDB into Solr.


~~~mermaid
graph TD
  subgraph Backend
    A[(ðŸƒ MongoDB)]
    B[[âš™ï¸ ETL Component\nNode.js + TypeScript]]
    C[(ðŸ”Ž Solr Index)]
  end

  subgraph Frontend
    D[[ðŸ–¥ï¸ Bartoc Frontend App]]
  end

  A -->|Extract_initial_load| B
  A -- Change_Stream --> B
  B -->|Transform_and_Load| C
  D -->|Query| C
  C -->|Results| D
~~~

### Project root structure
```pgsql
.
â”œâ”€â”€ api-test.http
â”œâ”€â”€ bartoc-etl.code-workspace
â”œâ”€â”€ config
â”‚Â Â  â”œâ”€â”€ config.default.json
â”‚Â Â  â””â”€â”€ config.json
â”œâ”€â”€ data
â”‚Â Â  â””â”€â”€ latest.ndjson
â”œâ”€â”€ docker
â”‚Â Â  â”œâ”€â”€ docker-compose.yml
â”‚Â Â  â”œâ”€â”€ Dockerfile
â”‚Â Â  â””â”€â”€ mongo-initdb.d
â”‚Â Â      â””â”€â”€ mongo_setup.sh
â”œâ”€â”€ eslint.config.mjs
â”œâ”€â”€ jest.config.mjs
â”œâ”€â”€ nodemon.json
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ README.md
â”œâ”€â”€ rorri.txt
â”œâ”€â”€ solr-configs
â”‚Â Â  â””â”€â”€ bartoc
â”‚Â Â      â””â”€â”€ conf
â”œâ”€â”€ src
â”‚Â Â  â”œâ”€â”€ conf
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ configValidation.ts
â”‚Â Â  â”‚Â Â  â””â”€â”€ conf.ts
â”‚Â Â  â”œâ”€â”€ data
â”‚Â Â  â”‚Â Â  â””â”€â”€ seedTerminologies.ts
â”‚Â Â  â”œâ”€â”€ errors
â”‚Â Â  â”‚Â Â  â””â”€â”€ errors.ts
â”‚Â Â  â”œâ”€â”€ extract
â”‚Â Â  â”‚Â Â  â””â”€â”€ readNdjson.ts
â”‚Â Â  â”œâ”€â”€ index.ts
â”‚Â Â  â”œâ”€â”€ load
â”‚Â Â  â”‚Â Â  â””â”€â”€ loadToSolr.ts
â”‚Â Â  â”œâ”€â”€ models
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ meta.ts
â”‚Â Â  â”‚Â Â  â””â”€â”€ terminology.ts
â”‚Â Â  â”œâ”€â”€ mongo
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ initMeta.ts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ mongo.ts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ terminologySchemaValidation.ts
â”‚Â Â  â”‚Â Â  â””â”€â”€ watchTerminologies.ts
â”‚Â Â  â”œâ”€â”€ server.ts
â”‚Â Â  â”œâ”€â”€ solr
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ CollectionOperation.ts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ SolrClient.ts
â”‚Â Â  â”‚Â Â  â””â”€â”€ SolrRequest.ts
â”‚Â Â  â”œâ”€â”€ tests
â”‚Â Â  â”‚Â Â  â””â”€â”€ add.test.ts
â”‚Â Â  â”œâ”€â”€ transform
â”‚Â Â  â”‚Â Â  â””â”€â”€ transformToSolr.ts
â”‚Â Â  â”œâ”€â”€ types
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ conf.d.ts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ jskos.ts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ solr.ts
â”‚Â Â  â”‚Â Â  â””â”€â”€ terminology.d.ts
â”‚Â Â  â”œâ”€â”€ utils
â”‚Â Â  â”‚Â Â  â””â”€â”€ loadConfig.ts
â”‚Â Â  â””â”€â”€ utils.ts
â””â”€â”€ tsconfig.json
```

### Setting Up a Local Solr Instance

A common approach is using Docker. For example:
```bash
docker run -d -p 8983:8983 --name solr solr:8
```

After starting Solr, you can create a new collection (for instance, named bartoc):
```bash
docker exec -it solr bin/solr create -c bartoc -n data_driven_schema_configs
```
This command creates a collection using a dynamic, data-driven schema which you can later modify.

##### Mounting a Custom Configset

you can mount your custom config set to a directory inside the container and then create your collection using that config set. For example:

1. Create a local folder with your custom configuration:
```pgsql
solr-configs/
  â””â”€â”€ your-configset/
      â””â”€â”€ conf/
          â”œâ”€â”€ schema.xml
          â””â”€â”€ solrconfig.xml
```

2. Mount it to a known location inside the container. If the default isnâ€™t available, you can choose another path (for instance, /configsets/your-configset):
```bash
docker run -d -p 8983:8983 --name solr-custom -v $(pwd)/solr-configs/your-configset:/configsets/your-configset solr:8
```

3. When creating the collection, tell Solr which config set to use. If you mounted it to /configsets/your-configset, create your collection with:
```bash
docker exec -it solr-custom bin/solr create -c bartoc -n your-configset
```

##### Comments on index schema
- Field Types:
  - *string* is used for non-tokenized fields (IDs, keywords).
  - *text_en* is configured with tokenizers and filters suitable for English text.
  - *pdate* and *pint* handle date and integer conversions.

- Fields:
Each field is defined with the proper attributes (indexed, stored, and multiValued where applicable) to match the mapping established.

- Dynamic Fields:
This section ensures that any unexpected or future fields following a naming convention (like *_s, *_txt, etc.) are handled gracefully.

- Copy Fields:
These allow the contents of title_en and description_en to be searched in a general-purpose catch-all field (text).

- Schema Metadata:
The uniqueKey is set to id, and default search behaviors are defined.